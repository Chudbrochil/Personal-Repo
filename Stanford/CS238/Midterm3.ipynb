{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthony Galczak\n",
    "# CS238 - Midterm 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "import itertools\n",
    "\n",
    "class POMDP:\n",
    "\n",
    "    def __init__(self, horizon, num_exams, model_param, r_false_fail, \n",
    "                 r_false_pass, p_false_fail, p_false_pass, p_qual):\n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.num_exams = num_exams\n",
    "        self.model_param = model_param\n",
    "        self.r_false_fail = r_false_fail\n",
    "        self.r_false_pass = r_false_pass\n",
    "        self.p_false_fail = p_false_fail\n",
    "        self.p_false_pass = p_false_pass\n",
    "        self.p_qual = p_qual\n",
    "        \n",
    "pom = POMDP(2, 3, 0.3, -1, -1, 0.15, 0.2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "def get_states(pom):\n",
    "    n = pom.num_exams\n",
    "    possible_states = [0,1]\n",
    "    return [i for i in itertools.product(possible_states, repeat = n)]\n",
    "def get_actions(pom):\n",
    "    n = pom.num_exams\n",
    "    possible_actions = [0,1]\n",
    "    return [i for i in itertools.product(possible_actions, repeat = n)]\n",
    "def get_observations(pom):\n",
    "    n = pom.num_exams\n",
    "    possible_observ = [-1,0,1]\n",
    "    return [i for i in itertools.product(possible_observ, repeat = n)]\n",
    "\n",
    "print(len(get_observations(pom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "0.0225\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "def transition(pom, state, action, next_state):\n",
    "    # Edge case, if we chose to take no action.\n",
    "    if sum(action) == 0:\n",
    "        if state == next_state:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Probability to pass any one exam.\n",
    "    prob_pass = pom.model_param / sum(action)\n",
    "    transition_prob = 1\n",
    "    for i in range(len(action)):\n",
    "        if action[i] == 1: # We are taking this exam.\n",
    "            if state[i] == 0 and next_state[i] == 0: # We fail\n",
    "                transition_prob *= (1 - prob_pass)\n",
    "            elif state[i] == 0 and next_state[i] == 1: # We pass\n",
    "                transition_prob *= prob_pass\n",
    "            # We don't have to handle the case where it's 1,1 since \n",
    "            # we can't \"unqualify\"\n",
    "    return transition_prob\n",
    "\n",
    "print(transition(pom, [0,1,0], [1,1,0], [1,1,0]))\n",
    "# Testing 2 exam passes at once.\n",
    "print(transition(pom, [0,0,0], [1,1,0], [1,1,0])) \n",
    "print(transition(pom, [0,1,0], [0,0,0], [0,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "def reward(pom, state, action, t):\n",
    "    if sum(state) == 3 and sum(action) > 0 and t == 3: # False fail\n",
    "        return pom.r_false_fail\n",
    "    elif sum(state) < 3 and sum(action) == 0: # False pass\n",
    "        return pom.r_false_pass\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(reward(pom, [1,0,0], [0,0,0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Q5\n",
    "def observation(pom, action, next_state, observ):\n",
    "    prob = 1\n",
    "    for i in range(len(observ)):\n",
    "        if action[i] == 1:\n",
    "            # If we didn't take that test, return 0.\n",
    "            if observ[i] == -1:\n",
    "                return 0\n",
    "            # Student fails, and is unqualified\n",
    "            elif observ[i] == 0 and next_state[i] == 0: \n",
    "                prob *= (1 - pom.p_false_fail)\n",
    "            # Student fails, but is qualified\n",
    "            elif observ[i] == 0 and next_state[i] == 1: \n",
    "                prob *= pom.p_false_pass\n",
    "            # Student passes, but is unqualified\n",
    "            elif observ[i] == 1 and next_state[i] == 0:\n",
    "                prob *= pom.p_false_fail\n",
    "            # Student passes, and is qualified\n",
    "            elif observ[i] == 1 and next_state[i] == 1: \n",
    "                prob *= (1 - pom.p_false_pass)\n",
    "        else:\n",
    "            prob /= 3\n",
    "\n",
    "    return prob\n",
    "\n",
    "print(sum(observation(pom, [1,1,1], [1,1,1], o) for o in get_observations(pom)))\n",
    "# Testing non-trivial observation.\n",
    "print(sum(observation(pom, [1, 0, 0], [1, 1, 1], o) for o in get_observations(pom))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, 0): 0.0009999999999999994, (0, 0, 1): 0.008999999999999996, (0, 1, 0): 0.008999999999999996, (0, 1, 1): 0.08099999999999999, (1, 0, 0): 0.008999999999999996, (1, 0, 1): 0.08099999999999999, (1, 1, 0): 0.08099999999999999, (1, 1, 1): 0.7290000000000001}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Q6\n",
    "def initbelief(pom):\n",
    "    b = {}\n",
    "    p_qual = pom.p_qual\n",
    "\n",
    "    for state in get_states(pom):\n",
    "        zeros = 3 - sum(state)\n",
    "        ones = sum(state)\n",
    "        b[state] = ((1 - p_qual) ** zeros) * (p_qual ** ones)\n",
    "\n",
    "    return b\n",
    "\n",
    "beliefs = initbelief(pom)\n",
    "print(beliefs) # Showing numerical values\n",
    "print(len(beliefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, 0): 8.499859752314077e-06, (0, 0, 1): 0.00040799326811107576, (0, 1, 0): 0.00040799326811107576, (0, 1, 1): 0.019583676869331643, (1, 0, 0): 0.00040799326811107576, (1, 0, 1): 0.019583676869331643, (1, 1, 0): 0.019583676869331646, (1, 1, 1): 0.9400164897279194}\n",
      "{(0, 0, 0): 0.00013359213535240805, (0, 0, 1): 0.0002829009925109818, (0, 1, 0): 0.006412422496915588, (0, 1, 1): 0.013579247640527132, (1, 0, 0): 0.006412422496915588, (1, 0, 1): 0.013579247640527132, (1, 1, 0): 0.30779627985194835, (1, 1, 1): 0.6518038867453027}\n"
     ]
    }
   ],
   "source": [
    "# Q7\n",
    "def update_belief(pom, b, action, observ):\n",
    "    new_belief = {}\n",
    "    for state in get_states(pom):\n",
    "        new_prob = observation(pom, action, state, observ) * b[state]\n",
    "        new_belief[state] = new_prob\n",
    "\n",
    "    total = sum(new_belief.values())\n",
    "    for state in get_states(pom):\n",
    "        new_belief[state] = (new_belief[state] * (1/total))\n",
    "\n",
    "    return new_belief\n",
    "\n",
    "print(update_belief(pom, beliefs, [1,1,1], [1,1,1]))\n",
    "# Showing that [1,1,0] increases in belief.\n",
    "print(update_belief(pom, beliefs, [1,1,1], [1,1,0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: (0, 0, 0) Expected Reward: -0.875\n",
      "Action: (0, 0, 1) Expected Reward: 0.0\n",
      "Action: (0, 1, 0) Expected Reward: 0.0\n",
      "Action: (0, 1, 1) Expected Reward: 0.0\n",
      "Action: (1, 0, 0) Expected Reward: 0.0\n",
      "Action: (1, 0, 1) Expected Reward: 0.0\n",
      "Action: (1, 1, 0) Expected Reward: 0.0\n",
      "Action: (1, 1, 1) Expected Reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Q8\n",
    "for action in get_actions(pom):\n",
    "    expected_reward = 0\n",
    "    for belief in beliefs:\n",
    "        expected_reward += (reward(pom, belief, action, 1) / 8)\n",
    "    print(\"Action: {0} Expected Reward: {1}\".format(action, expected_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Q9\n",
    "def lastreward(pom, state, observ):\n",
    "    found_false_pass = False\n",
    "    actual_fail = False\n",
    "    for i in range(len(observ)):\n",
    "        # If we fail them, but they were qualified\n",
    "        if observ[i] == 0 and state[i] == 1: \n",
    "            return pom.r_false_fail\n",
    "        # If we pass them, but they weren't qualified\n",
    "        elif observ[i] == 1 and state[i] == 0: \n",
    "            found_false_pass = True\n",
    "        elif observ[i] == 0 and state[i] == 0:\n",
    "            actual_fail = True\n",
    "\n",
    "    # If they passed something they shouldn't have \n",
    "    # and didn't fail another subject\n",
    "    if found_false_pass == True and actual_fail == False:\n",
    "        return pom.r_false_pass\n",
    "\n",
    "    return 0\n",
    "\n",
    "print(lastreward(pom, [1,1,1], [1,1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18050000000000005\n",
      "-1\n",
      "-0.0360395\n"
     ]
    }
   ],
   "source": [
    "#Q10\n",
    "def expected_utility(pom, state, observ):\n",
    "    \n",
    "    # If they failed an exam, we are going to have them re-take all \n",
    "    # and try again.\n",
    "    if 0 in observ:\n",
    "        action = [1,1,1]\n",
    "        utility = 0\n",
    "        \n",
    "        for next_state in get_states(pom):\n",
    "            # Odds we transition to the next state multiplied by \n",
    "            # observation probability\n",
    "            prob = transition(pom, state, action, next_state) * \\\n",
    "                observation(pom, action, next_state, observ)\n",
    "            utility += prob * lastreward(pom, next_state, observ)\n",
    "            \n",
    "        return utility\n",
    "        \n",
    "    # If they didn't fail an exam, there is a deterministic evaluation \n",
    "    # that follows. i.e. Either their state is [1,1,1] and we return \n",
    "    # 0 or it isn't and we return -1.\n",
    "    else:\n",
    "        return lastreward(pom, state, observ)\n",
    "    \n",
    "    \n",
    "print(expected_utility(pom, [1,1,1], [1,1,0]))\n",
    "# They aren't qualified, but they magically passed everything\n",
    "print(expected_utility(pom, [0,0,0], [1,1,1]))\n",
    "# Hail mary, study and try to pass everything\n",
    "print(expected_utility(pom, [0,0,0], [0,0,0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.8350423836494987, -7.264989126417368, -7.264989126417369, -46.18251633007208, -7.2706779360190605, -46.46311917971479, -46.4631191797148, -1699.1588239345579]\n",
      "[-0.0018350423836494974, -0.06538490213775629, -0.06538490213775629, -3.740783822735838, -0.06543610142417151, -3.7635126535568975, -3.7635126535568983, -1238.6867826482928]\n"
     ]
    }
   ],
   "source": [
    "#Q11\n",
    "def compute_alpha(state, action, t, val):\n",
    "    \n",
    "    if t == 3:\n",
    "        return lastreward(pom, state, action)\n",
    "        \n",
    "    r = reward(pom, state, action, t)\n",
    "    \n",
    "    for next_state in get_states(pom):\n",
    "        \n",
    "        # If they failed an exam, make them take everything again.\n",
    "        if 0 in next_state:\n",
    "            action = [1,1,1]\n",
    "        else:\n",
    "            action = [0,0,0]\n",
    "        \n",
    "        t_prob = transition(pom, state, action, next_state)\n",
    "        \n",
    "        for observ in get_observations(pom):\n",
    "            val += t_prob*observation(pom, action, next_state, observ) \\\n",
    "                * compute_alpha(next_state, action, t + 1, val)\n",
    "            \n",
    "    return val\n",
    "\n",
    "alpha = [compute_alpha(state, [1,1,1], 1, 0) for \\\n",
    "         state in get_states(pom)]\n",
    "print(alpha)\n",
    "\n",
    "# Getting initial belief, then pulling it out of the map to dot product \n",
    "# with our alpha vector.\n",
    "initial_b = initbelief(pom)\n",
    "expected_utility_vector = []\n",
    "i = 0\n",
    "states = get_states(pom)\n",
    "for state in get_states(pom):\n",
    "    new_utility = initial_b[state] * alpha[i]\n",
    "    expected_utility_vector.append(new_utility)\n",
    "    i += 1\n",
    "print(expected_utility_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5379721925327552, -6.42190958625785, -6.421909586257849, -57.3832636842079, -6.437116576458768, -58.15067294770366, -58.15067294770365, -1.6695939778125723]\n",
      "[-0.0015379721925327541, -0.05779718627632062, -0.05779718627632061, -4.648044358420839, -0.05793404918812889, -4.710204508763996, -4.7102045087639945, -1.2171340098253653]\n"
     ]
    }
   ],
   "source": [
    "#Q12\n",
    "def compute_alpha2(state, action, t, val):\n",
    "    \n",
    "    if t == 3:\n",
    "        return lastreward(pom, state, action)\n",
    "        \n",
    "    r = reward(pom, state, action, t)\n",
    "    \n",
    "    for next_state in get_states(pom):\n",
    "        \n",
    "        # Get new action based on policy of: \n",
    "        # \"Retake the exams they fail at each timestep\"\n",
    "        action = []\n",
    "        for i in range(len(state)):\n",
    "            if state[i] == 0:\n",
    "                action.append(1)\n",
    "            else:\n",
    "                action.append(0)\n",
    "                        \n",
    "        t_prob = transition(pom, state, action, next_state)\n",
    "        \n",
    "        for observ in get_observations(pom):\n",
    "            val += t_prob*observation(pom, action, next_state, observ) * \\\n",
    "                compute_alpha2(next_state, action, t + 1, val)\n",
    "            \n",
    "    return val\n",
    "\n",
    "alpha2 = [compute_alpha2(state, [1,1,1], 1, 0) for \\\n",
    "          state in get_states(pom)]\n",
    "print(alpha2)\n",
    "\n",
    "# Getting initial belief, then pulling it out of the map to dot product \n",
    "# with our alpha vector.\n",
    "initial_b = initbelief(pom)\n",
    "expected_utility_vector2 = []\n",
    "i = 0\n",
    "states = get_states(pom)\n",
    "for state in get_states(pom):\n",
    "    new_utility = initial_b[state] * alpha2[i]\n",
    "    expected_utility_vector2.append(new_utility)\n",
    "    i += 1\n",
    "print(expected_utility_vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
